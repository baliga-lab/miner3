{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Before you get started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data formatting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MINER is optimized for expression data of the form log2(TPM+1) or log2(FPKM+1). Expression data in counts format is not currently supported. If your data is in counts format, consider first transforming to log2(cpm+1) with edgeR.\n",
    "\n",
    "If expression data is not Homo Sapiens, a reference database must be provided for mechanistic inference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Begin miner analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import standard dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "attempted relative import with no known parent package",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 25\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m metrics\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tree\n\u001b[0;32m---> 25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m miner\n\u001b[1;32m     26\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39mrun_line_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmatplotlib\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minline\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     27\u001b[0m plt\u001b[38;5;241m.\u001b[39mstyle\u001b[38;5;241m.\u001b[39muse(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mggplot\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mImportError\u001b[0m: attempted relative import with no known parent package"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from numpy import random as rd\n",
    "import os\n",
    "import json\n",
    "from sklearn.decomposition import PCA\n",
    "import multiprocessing, multiprocessing.pool\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "from collections import Counter\n",
    "from sklearn.manifold import TSNE\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn import metrics\n",
    "from sklearn import tree\n",
    "from . import miner\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create directory to save output files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the miner directory\n",
    "proj_path = os.path.join(os.path.expanduser('~'),'Projects','miner3')\n",
    "input_path = os.path.join(proj_path, 'miner_mindata')\n",
    "\n",
    "# create name for results folder where output files will be saved\n",
    "resultsFolder = \"miner_network_results\"\n",
    "\n",
    "# create results directory\n",
    "resultsDirectory = os.path.join(proj_path,resultsFolder)\n",
    "if not os.path.isdir(resultsDirectory):\n",
    "    os.mkdir(resultsDirectory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load reference dictionary for mechanistic inference (skip if using default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #provide absolute path to your .csv-format reference database\n",
    "# filename = os.path.join(os.path.split(os.getcwd())[0],\"data\",\"reference_database_example.csv\")\n",
    "# #provide absolute path to the miner/data/network_dictionaries directory where your database will be stored\n",
    "# network_dictionaries_path = os.path.join(os.path.split(os.getcwd())[0],\"data\",\"network_dictionaries\")\n",
    "# #name your reference database and use the extension \".pkl\"\n",
    "# dictionaryName = \"reference_database.pkl\"\n",
    "# #import and save your reference database to the Python pickle format for future use\n",
    "# reference_mechanistic_database = miner.fileToReferenceDictionary(filename,os.path.join(network_dictionaries_path,dictionaryName))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Load and pre-process data; set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load expression Data\n",
    "expressionFile = os.path.join(input_path,\"expression\",\"IA12Zscore.csv\")\n",
    "id_names = os.path.join(input_path, \"identifier_mappings.txt\")\n",
    "expressionData, conversionTable = miner.preprocess(expressionFile, id_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize pre-processed expression data\n",
    "individual_expression_data = [expressionData.iloc[:,i] for i in range(50)]\n",
    "_ = plt.boxplot(individual_expression_data)\n",
    "plt.title(\"Patient expression profiles\",fontsize=14)\n",
    "plt.ylabel(\"Relative expression\", fontsize=14)\n",
    "plt.xlabel(\"Sample ID\", fontsize=14)\n",
    "plt.figure()\n",
    "_ = plt.hist(expressionData.iloc[0,:],bins=100,alpha=0.75)\n",
    "plt.title(\"Expression of single gene\", fontsize=14)\n",
    "plt.ylabel(\"Frequency\", fontsize=14)\n",
    "plt.xlabel(\"Relative expression\", fontsize=14)\n",
    "plt.figure()\n",
    "_ = plt.hist(expressionData.iloc[:,0],bins=200,color=[0,0.4,0.8],alpha=0.75)\n",
    "plt.ylim(0,350)\n",
    "plt.title(\"Expression of single patient sample\", fontsize=14)\n",
    "plt.ylabel(\"Frequency\", fontsize=14)\n",
    "plt.xlabel(\"Relative expression\", fontsize=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# minimum number of genes that form an acceptable coexpression cluster:\n",
    "minNumberGenes = 6 #bulk RNAseq default=6;single cell RNAseq default=6\n",
    "\n",
    "# minimum correlation coefficient for an acceptable regulator-cluster association \n",
    "minCorrelation = 0.2 #bulk RNAseq default=0.2;single cell RNAseq default=0.05\n",
    "\n",
    "# minimum number of genes that form an acceptable coexpression cluster and have share binding site for regulator:\n",
    "minNumberRegulonGenes = 5 #bulk RNAseq default=5;single cell RNAseq default=4\n",
    "\n",
    "# choose database: if supplying your own database, use mechanistic_database = reference_mechanistic_database\n",
    "mechanistic_database = \"tfbsdb2_tf_to_genes.pkl\" #default option\n",
    "database_path = os.path.join(proj_path, 'miner', 'data', 'network_dictionaries', mechanistic_database)\n",
    "#mechanistic_database = reference_mechanistic_database #use if supplying your own database\n",
    "\n",
    "# number of cores available for multiprocessing\n",
    "numCores = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Co-expression clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Network inference may take several minutes. \n",
    "# Prompts will print at 0, 20, 40, 60, 80, and 100% complete\n",
    "\n",
    "t1 = time.time() \n",
    "# generate a list of coexpressed gene clusters, all of which have length >= minNumberGenes\n",
    "initialClusters = miner.cluster(expressionData,minNumberGenes = minNumberGenes,minNumberOverExpSamples=4,maxSamplesExcluded=0.50,random_state=17,overExpressionThreshold=80) \n",
    "# revise initialClusters to combine highly correlated clusters and keep only those with significant coexpression\n",
    "revisedClusters = miner.reviseInitialClusters(initialClusters,expressionData)\n",
    "# write revisedClusters to .json file\n",
    "miner.write_json(revisedClusters,os.path.join(resultsDirectory,\"coexpressionDictionary.json\"))\n",
    "t2 = time.time()\n",
    "print(\"Completed coexpression clustering in {:.2f} minutes\".format((t2-t1)/60.))\n",
    "\n",
    "# retrieve first three clusters for visual inspection\n",
    "first_clusters = np.hstack([revisedClusters[i] for i in np.arange(3).astype(str)])\n",
    "\n",
    "# visualize background expression\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.imshow(expressionData.loc[np.random.choice(\n",
    "    expressionData.index,len(first_clusters),\n",
    "    replace=False),:],aspect=\"auto\",cmap=\"viridis\",vmin=-1,vmax=1)\n",
    "plt.grid(False)\n",
    "plt.ylabel(\"Genes\", fontsize=20)\n",
    "plt.xlabel(\"Samples\", fontsize=20)\n",
    "plt.title(\"Random selection of genes\", fontsize=20)\n",
    "\n",
    "# visualize first 10 clusters\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.imshow(expressionData.loc[first_clusters,:],aspect=\"auto\",cmap=\"viridis\",vmin=-1,vmax=1)\n",
    "plt.grid(False)\n",
    "plt.ylabel(\"Genes\", fontsize=20)\n",
    "plt.xlabel(\"Samples\", fontsize=20)\n",
    "plt.title(\"First 3 clusters\", fontsize=20)\n",
    "\n",
    "# report coverage\n",
    "print(\"Number of genes clustered: {:d}\".format(len(set(np.hstack(initialClusters)))))\n",
    "print(\"Number of unique clusters: {:d}\".format(len(revisedClusters)))\n",
    "\n",
    "t3 = time.time()\n",
    "print(\"Completed clustering module in {:.2f} minutes\".format((t3-t1)/60.))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Mechanistic inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "t1 = time.time()\n",
    "# get first principal component axes of clusters\n",
    "axes = miner.principal_df(revisedClusters,expressionData,subkey=None,minNumberGenes=1)\n",
    "# analyze revised clusters for enrichment in relational database (default: transcription factor binding site database)\n",
    "mechanisticOutput = miner.mechanisticInference(axes,revisedClusters,expressionData,\n",
    "                                               correlationThreshold=minCorrelation,numCores=numCores,\n",
    "                                               database_path=database_path)\n",
    "# write mechanistic output to .json file\n",
    "miner.write_json(mechanisticOutput,os.path.join(resultsDirectory,\"mechanisticOutput.json\"))\n",
    "# order mechanisticOutput as {tf:{coexpressionModule:genes}} \n",
    "coregulationModules = miner.getCoregulationModules(mechanisticOutput)\n",
    "# write coregulation modules to .json file\n",
    "miner.write_json(coregulationModules,os.path.join(resultsDirectory,\"coregulationModules.json\"))\n",
    "# get final regulons by keeping genes that requently appear coexpressed and associated to a common regulator\n",
    "regulons = miner.getRegulons(coregulationModules,minNumberGenes=minNumberRegulonGenes,freqThreshold = 0.333)\n",
    "# reformat regulon dictionary for consistency with revisedClusters and coexpressionModules\n",
    "regulonModules, regulonDf = miner.regulonDictionary(regulons)\n",
    "# write regulonDf to csv using preferred gene name identifiers\n",
    "regulonDf.to_csv(os.path.join(resultsDirectory,\"regulonDf.csv\"))\n",
    "# write regulons to json file\n",
    "miner.write_json(regulonModules,os.path.join(resultsDirectory,\"regulons.json\"))\n",
    "# define coexpression modules as composite of coexpressed regulons\n",
    "coexpressionModules = miner.getCoexpressionModules(mechanisticOutput)\n",
    "# write coexpression modules to .json file\n",
    "miner.write_json(coexpressionModules,os.path.join(resultsDirectory,\"coexpressionModules.json\"))\n",
    "# Get eigengenes for all modules\n",
    "eigengenes = miner.getEigengenes(regulonModules,expressionData,regulon_dict=None,saveFolder=None)\n",
    "eigenScale = np.percentile(expressionData,95)/np.percentile(eigengenes,95)\n",
    "eigengenes = eigenScale*eigengenes\n",
    "eigengenes.index = np.array(eigengenes.index).astype(str)\n",
    "#write eigengenes to .csv\n",
    "eigengenes.to_csv(os.path.join(resultsDirectory,\"eigengenes.csv\"))\n",
    "\n",
    "t2 = time.time()\n",
    "print(\"Completed mechanistic inference in {:.2f} minutes\".format((t2-t1)/60.))\n",
    "print(\"Inferred network with {:d} regulons, {:d} regulators, and {:d} co-regulated genes\".format(len(regulonDf.Regulon_ID.unique()),len(regulonDf.Regulator.unique()),len(regulonDf.Gene.unique())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Network mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = time.time()\n",
    "# select reference dictionary for downstream analysis (revisedClusters, coexpressionModules, or regulonModules)\n",
    "referenceDictionary = regulonModules\n",
    "# create a background matrix used for statistical hypothesis testing\n",
    "bkgd = miner.background_df(expressionData)\n",
    "# for each cluster, give samples that show high coherent cluster activity\n",
    "overExpressedMembers = miner.biclusterMembershipDictionary(referenceDictionary,bkgd,label=2,p=0.05)\n",
    "# for each clus|ter, give samples that show low coherent cluster activity\n",
    "underExpressedMembers = miner.biclusterMembershipDictionary(referenceDictionary,bkgd,label=0,p=0.05)\n",
    "# for each cluster, give samples that do not show coherent cluster activity\n",
    "# dysregulatedMembers = miner.biclusterMembershipDictionary(referenceDictionary,bkgd,label=\"excluded\")\n",
    "# # for each cluster, give samples that show coherent cluster activity, despite magnitude of expression\n",
    "# coherentMembers = miner.biclusterMembershipDictionary(referenceDictionary,bkgd,label=\"included\")\n",
    "\n",
    "# write membership matrices to .csv file\n",
    "overExpressedMembersMatrix = miner.membershipToIncidence(overExpressedMembers,expressionData)\n",
    "overExpressedMembersMatrix.to_csv(os.path.join(resultsDirectory,\"overExpressedMembers.csv\"))\n",
    "underExpressedMembersMatrix = miner.membershipToIncidence(underExpressedMembers,expressionData)\n",
    "underExpressedMembersMatrix.to_csv(os.path.join(resultsDirectory,\"underExpressedMembers.csv\"))\n",
    "# dysregulatedMembersMatrix = miner.membershipToIncidence(dysregulatedMembers,expressionData)\n",
    "# dysregulatedMembersMatrix.to_csv(os.path.join(resultsDirectory,\"dysregulatedMembers.csv\"))\n",
    "# coherentMembersMatrix = miner.membershipToIncidence(coherentMembers,expressionData)\n",
    "# coherentMembersMatrix.to_csv(os.path.join(resultsDirectory,\"coherentMembers.csv\"))\n",
    "\n",
    "t2 = time.time()\n",
    "print(\"Completed patient mapping in {:.2f} minutes\".format((t2-t1)/60.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize network activity across individual samples\n",
    "plt.figure(figsize=(7,7))\n",
    "network_activity_heatmap = overExpressedMembersMatrix-underExpressedMembersMatrix\n",
    "plt.imshow(network_activity_heatmap,cmap=\"bwr\",vmin=-1,vmax=1,aspect=\"auto\")\n",
    "plt.title(\"Network activity\", fontsize=16)\n",
    "plt.ylabel(\"Regulons\", fontsize=16)\n",
    "plt.xlabel(\"Samples\", fontsize=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Expand regulons (optional, not default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "t1 = time.time()\n",
    "tfbsdbGenes_file = os.path.join(input_path, \"network_dictionaries\",\"tfbsdb_genes_to_tf.pkl\")\n",
    "expandedRegulons = miner.parallelRegulonExpansion(eigengenes,regulonModules,regulonDf,\n",
    "                                                  expressionData,tfbsdbGenes_file,\n",
    "                                                  overExpressedMembersMatrix,\n",
    "                                                  corrThreshold = 0.25,auc_threshold = 0.70,\n",
    "                                                  numCores=5)\n",
    "\n",
    "regulonIDtoRegulator = miner.regulonIdToRegulator(regulonDf)\n",
    "expandedRegulonDf = miner.regulonDictToDf(expandedRegulons,regulonIDtoRegulator)\n",
    "t2 = time.time()\n",
    "print(\"Completed regulon expansion in {:.2f} minutes\".format((t2-t1)/float(60.)))\n",
    "\n",
    "expandedEigengenes = miner.getEigengenes(expandedRegulons,expressionData,regulon_dict=None,saveFolder=None)\n",
    "eigenScale = np.percentile(expressionData,95)/np.percentile(expandedEigengenes,95)\n",
    "expandedEigengenes = eigenScale*expandedEigengenes\n",
    "expandedEigengenes.index = np.array(expandedEigengenes.index).astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expandedEigengenes.to_csv(os.path.join(resultsDirectory,\"expanded_eigengenes.csv\"))\n",
    "expandedRegulonDf.to_csv(os.path.join(resultsDirectory,\"expanded_regulonDf.csv\"))\n",
    "miner.write_json(expandedRegulons,os.path.join(resultsDirectory,\"expanded_regulons.json\"))\n",
    "print(\"Expanded network to {:d} regulons, {:d} regulators, and {:d} co-regulated genes\".format(len(expandedRegulonDf.Regulon_ID.unique()),\n",
    "                                                                                                 len(expandedRegulonDf.Regulator.unique()),\n",
    "                                                                                                 len(expandedRegulonDf.Gene.unique())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Causal inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load mutation matrices\n",
    "common_mutations_file = os.path.join(input_path,\"mutations\",\"commonMutations.csv\")\n",
    "common_mutations = pd.read_csv(common_mutations_file,index_col=0,header=0)\n",
    "\n",
    "translocations_file = os.path.join(input_path,\"mutations\",\"translocationsIA12.csv\")\n",
    "translocations = pd.read_csv(translocations_file,index_col=0,header=0)\n",
    "\n",
    "cytogenetics_file = os.path.join(input_path,\"mutations\",\"cytogenetics.csv\")\n",
    "cytogenetics = pd.read_csv(cytogenetics_file,index_col=0,header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Perform causal analysis for each mutation matrix\n",
    "mut_matrix = common_mutations.copy()\n",
    "referenceDictionary = regulonModules\n",
    "referenceRegulonDf = regulonDf\n",
    "referenceDf = eigengenes\n",
    "\n",
    "miner.causalNetworkAnalysis(regulon_matrix=referenceRegulonDf.copy(),expression_matrix=expressionData.copy(),reference_matrix=referenceDf.copy(),mutation_matrix=mut_matrix,resultsDirectory=os.path.join(resultsDirectory,\"causal_analysis\"),minRegulons=1,significance_threshold=0.05,causalFolder=\"causal_results_common_mutations\")\n",
    "\n",
    "mut_matrix = translocations.copy()\n",
    "miner.causalNetworkAnalysis(regulon_matrix=referenceRegulonDf.copy(),expression_matrix=expressionData.copy(),reference_matrix=referenceDf.copy(),mutation_matrix=mut_matrix,resultsDirectory=os.path.join(resultsDirectory,\"causal_analysis\"),minRegulons=1,significance_threshold=0.05,causalFolder=\"causal_results_translocations\")\n",
    "\n",
    "mut_matrix = cytogenetics.copy()\n",
    "miner.causalNetworkAnalysis(regulon_matrix=referenceRegulonDf.copy(),expression_matrix=expressionData.copy(),reference_matrix=referenceDf.copy(),mutation_matrix=mut_matrix,resultsDirectory=os.path.join(resultsDirectory,\"causal_analysis\"),minRegulons=1,significance_threshold=0.05,causalFolder=\"causal_results_cytogenetics\")\n",
    "\n",
    "# compile all causal results\n",
    "causal_directory = os.path.join(resultsDirectory,\"causal_analysis\")\n",
    "causal_results = miner.readCausalFiles(causal_directory)\n",
    "causal_results.to_csv(os.path.join(resultsDirectory,\"completeCausalResults.csv\"))\n",
    "causal_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtered causal results\n",
    "causal_results_regulon_filtered = causal_results[causal_results[\"-log10(p)_Regulon_stratification\"]>=-np.log10(0.05)]\n",
    "causal_results_aligned = causal_results_regulon_filtered[causal_results_regulon_filtered.Fraction_of_edges_correctly_aligned>=0.5]\n",
    "causal_results_aligned_correlated = causal_results_aligned[causal_results_aligned[\"RegulatorRegulon_Spearman_p-value\"]<=0.05]\n",
    "causal_results_stratified_aligned_correlated = causal_results_aligned_correlated[causal_results_aligned_correlated[\"-log10(p)_MutationRegulatorEdge\"]>=-np.log10(0.05)]\n",
    "\n",
    "# for all causal flows, \n",
    "# the regulon is differentially active w.r.t the mutation,\n",
    "# the regulator is differentially active w.r.t the mutation,\n",
    "# the regulator is significantly correlated to the regulon,\n",
    "# and the directionality of at least half of the differentially active targets \n",
    "# downstream of the regulator are consistent with the perturbation from the mutation\n",
    "\n",
    "causal_results_stratified_aligned_correlated.to_csv(os.path.join(resultsDirectory,\"filteredCausalResults.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Subtype discovery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Infer transcriptional states\n",
    "minClusterSize = int(np.ceil(0.01*expressionData.shape[1]))\n",
    "referenceMatrix = overExpressedMembersMatrix-underExpressedMembersMatrix\n",
    "primaryMatrix = overExpressedMembersMatrix\n",
    "primaryDictionary = overExpressedMembers\n",
    "secondaryMatrix = underExpressedMembersMatrix\n",
    "secondaryDictionary = underExpressedMembers\n",
    "\n",
    "states, centroidClusters = miner.inferSubtypes(referenceMatrix,primaryMatrix,secondaryMatrix,primaryDictionary,secondaryDictionary,minClusterSize = int(np.ceil(0.01*expressionData.shape[1])),restricted_index=None)\n",
    "states_dictionary = {str(i):states[i] for i in range(len(states))}\n",
    "miner.write_json(states_dictionary,os.path.join(resultsDirectory,\"transcriptional_states.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Infer transcriptional programs\n",
    "reference_df = eigengenes.copy()\n",
    "programs, _ = miner.mosaic(dfr=reference_df,clusterList=centroidClusters,minClusterSize_x=int(np.ceil(0.01*expressionData.shape[1])),minClusterSize_y=5,allow_singletons=False,max_groups=50,saveFile=os.path.join(resultsDirectory,\"regulon_activity_heatmap.pdf\"),random_state=12)   \n",
    "transcriptional_programs, program_regulons = miner.transcriptionalPrograms(programs,referenceDictionary)\n",
    "program_list = [program_regulons[(\"\").join([\"TP\",str(i)])] for i in range(len(program_regulons))]\n",
    "programs_dictionary = {str(i):program_list[i] for i in range(len(program_list))}\n",
    "miner.write_json(programs_dictionary,os.path.join(resultsDirectory,\"transcriptional_programs.json\"))\n",
    "mosaicDf = reference_df.loc[np.hstack(program_list),np.hstack(states)]\n",
    "mosaicDf.to_csv(os.path.join(resultsDirectory,\"regulons_activity_heatmap.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfr = overExpressedMembersMatrix-underExpressedMembersMatrix\n",
    "mtrx = dfr.loc[np.hstack(program_list),np.hstack(states)]\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.imshow(mtrx,cmap=\"bwr\",vmin=-1,vmax=1,aspect=float(mtrx.shape[1])/float(mtrx.shape[0]))\n",
    "plt.grid(False)\n",
    "plt.savefig(os.path.join(resultsDirectory,\"mosaic_all.pdf\"),bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine activity of transcriptional programs in each sample\n",
    "statesDf = miner.reduceModules(df=dfr.loc[np.hstack(program_list),np.hstack(states)],programs=program_list,states=states,stateThreshold=0.50,saveFile=os.path.join(resultsDirectory,\"transcriptional_programs.pdf\"))\n",
    "\n",
    "# Cluster patients into subtypes and give the activity of each program in each subtype\n",
    "programsVsStates = miner.programsVsStates(statesDf,states,filename=os.path.join(resultsDirectory,\"programs_vs_states.pdf\"),showplot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
